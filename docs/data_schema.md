# Package Analysis Data Schema

This document descibes the format of the JSON results files produced by Package analysis.

## Dynamic Analysis

This is the current structure of JSON files written by dynamic analysis.
The format has evolved from the beginning of the project, without much thought given to the design.

### JSON schema

```js
{
	"Package": {
		"Ecosystem": string,
		"Name": string,
		"Version": string
	},
	"CreatedTimestamp": integer,
	"Analysis": map[string]{
		"Status": string,
		"Stdout": string,
		"Stderr": string,
		"Files": [ {
			"Path": string,
			"Read": boolean,
			"Write": boolean,
			"Delete": boolean
		} ],
		"Sockets": [ {
			"Address": string,
			"Port": int,
			"Hostnames": [ string ]
		} ],
		"Commands": [ {
			"Command": [ string ],
			"Environment": [ string ]
		} ],
		"DNS": [ {
			"Class": string,
			"Queries": [ {
				"Hostname": string,
				"Types": [ "A", "AAAA" ]
			} ]
		} ]
	}
}

```

The next section describes the meaning of each field.

### Package object
The package or key object is used to identify an analysis run for a specific artifact from an open source package repository. This object is required.

#### Ecosystem field
A string enum identifying the open source package repository the artifact belongs to. Currently supported values are "pypi", "npm", "packagist", "rubygems", "crates.io". This field is required.

#### Name field
A string identifying the open source package. This field is required.

#### Version field
A string identifying the specific version of the package. This field is required.

#### CreatedTimestamp field
CreatedTimestamp is an integer UTC unix timestamp (seconds) of when the analysis was performed.  This field is required.

### Analysis/Results object

#### Phase field/key
An enum string identifying the specific dynamic analysis phase. Currently supported values are "install" and "import", with an "execute" phase coming soon. This field is required.

#### Status field
An enum string identifying whether the analysis completed with or without errors

#### Stdout and Stderr fields
These are both base64 encoded strings from stdout and stderr output generated by the sandbox during execution. They are limited to 4K bytes each. These fields are optional.

### File object
The file object aggregates together what file operations were observed on a given path during execution. This data is parsed from the strace log output from the sandbox. The objects are optional.

Unfortunately any temporal relationship between different operations is not represented. For example, it is impossible to know from this object if a file was created and then deleted, or deleted and then created.

#### Path field
A string containing the path name of the file. This field is required.

#### Read field
A boolean value indicating whether or not the file was opened for reading. This field is required.

#### Write field
A boolean value indicating whether or not the file was opened for writing. This field is required.

#### Delete field
A boolean value indicating whether or not the file was deleted. This field is required.

### Socket object
The file object aggregates together any socket operations observed during execution. These operations are gathered from the strace log output from the sandbox, not the network pcap. The objects are optional.

#### Address field
A string containing either an IPv4 or IPv6 address. This field is required.

#### Port field
An integer containing the operating system port used by the socket. This field is 0 if a port cannot be determined.

#### Hostnames array
An array of strings containing possible hostnames that correspond to this address. This data is populated from the DNS data collected during analysis. This field is optional.

### Command object
The command object aggregates together and exec operations observed during execution. These operations are gathered from the strace log output from the sandbox. The objects are technically optional, but should always be present.

#### Command array
An array of strings containing all of the arguments passed to execve. The first item indicates the binary being used. There should be at least one entry in the array.

#### Environment array/object
The environment passed to execve. In the V0 case each string is an environment variable in the form "name=value". In the V1 case key is the characters before the first =, and value the remaining characters. This field is optional, but usually present.

### DNS object
The DNS object aggregates together any UDP DNS requests observed during execution. These operations are gathered from a network pcap. The objects are optional.

#### Class field
A string containing the network class. Usually this is "IN" for "internet", but other supported values are recorded. This field is required.

#### Queries object
This captures the query part of the request, with hostname tracking the specific hostname being queried, and types the DNS data types being queried for. This array must have at least one entry.



## Static Analysis

This is the current structure of the JSON files written by static analysis.
The top-level identifying keys have been revised a little bit from the dynamic analysis schema.
The struct that is serialized to produce this JSON data is located at `pkg/api/staticanalysis/record.go`.


### JSON schema

```js
{
  "schema_version": string,
  "ecosystem": string,
  "name": string,
  "version": string,
  "created": timestamp,
  "results": {
    "files": [
      {
        "filename": string,
        "detected_type": string,
        "size": int,
        "sha256": string,
        "line_lengths": [
          { "value": int, "count": int }
        ],
        "js": {
          "identifiers": [
            { "name": string, "type": string, "entropy": float64 }
          ],
          "string_literals": [
            { "value": string, "raw": string, "entropy": float64 }
          ],
          "int_literals": [
            { "value": int, "raw": string }
          ],
          "float_literals": [
            { "value": float, "raw": string }
          ],
          "comments": [
            { "text": string }
          ]
        },
        "identifier_lengths": [
          { "value": int, "count": int }
        ],
        "string_lengths": [
          { "value": int, "count": int }
        ],
        "suspicious_identifiers": [
          { "name": string, "rule": string }
        ],
        "escaped_strings": [
          { "value": string, "raw": string, "levenshtein_dist": float }
        ],
        "base64_strings": [ string ],
        "hex_strings": [ string ],
        "ip_addresses": [ string ],
        "urls": [ string ]
      }
    ]
  }
}
```

The next section describes the meaning of each field.

### Top-level object


#### `schema_version`
Identifies the specific version of the remaining data. There is not yet any specific format for this string. The initial version of this schema has the version string set to “1.0”

#### `ecosystem`
Identifies the open source package repository of the package being analyzed. Corresponds to an enum value; supported values are "pypi", "npm", "packagist", "rubygems", "crates.io"

#### `name`
The name of the package being analyzed

#### `version`
The version string of the package being analyzed, as reported by the ecosystem’s package manager.
No distinction is made between platform-specific or source/binary releases, other than what is already included in the official version string. In particular, extra information captured in the artifact filename is not incorporated here.

#### `created`
UTC RFC3339 string timestamp of when the analysis was completed

#### `results`
Contains all result data from the static analysis; see description below

### `results` object

#### `files`
List of static analysis results, one per file contained in the analyzed package tarball. Files are enumerated in lexical order. Symlinks or special files such as device files, sockets and pipes are excluded. Each item corresponds to a FileResult object in Go; see description below.

### `FileResult` object

#### `filename`
Path of the file, relative to the package archive root

#### `detected_type`
Filetype as determined by running the `file` command, which is included in most standard Linux distributions. Omitted if the `basic` analysis task was not run.

#### `size`
Size of the file in bytes. Omitted if the `basic` analysis task was not run.

#### `sha256`
SHA256 hashsum of the file. Omitted if the `basic` analysis task was not run.

#### `line_lengths`
Counts of line lengths in the file. This is represented as a list of (length, count) pairs. For example, a file with 4 lines of lengths 20, 30, 20, 30 characters respectively would have a `line_lengths` of `[{ "value": 20, "count": 2 }, { "value": 30, "count", 2 }]`. Omitted if the `basic` analysis task was not run.

#### `js` (optional)
Contains results from the `parsing` analysis task; this is raw data obtained from parsing as JavaScript source code. If the JS parser reports syntax errors while parsing the file, the file is assumed to not be a JavaScript source file. Omitted if the `parsing` analysis task was not run or there is no data. See further description of the `js` object below.

#### `identifier_lengths`
Counts of lengths of identifiers found during parsing. This is represented as a list of (length, count) pairs in the same format as the `line_lengths` field above. Omitted if the `signals` analysis task was not run or there is no data.


#### `string_lengths`
Counts of lengths of string literals found during parsing. This is represented as a list of (length, count) pairs in the same format as the `line_lengths` field above. Omitted if the `signals` analysis task was not run or there is no data.

#### `suspicious_identifiers`
Identifiers which match one of a list of inbuilt rules. Each record contains the following fields:
`name` - Identifier name as reported in the parsing section
`rule` - Name of the rule that the identifier name matched against
Omitted if the `signals` analysis task was not run or there is no data.

#### `escaped_strings`
String literals which contain a lot of escape characters. Each record contains the following fields:
`value` - String value as defined in the parsing section
`raw` - Raw value as defined in the parsing section
`levenshtein_dist` - Levenshtein distance between the value and the raw representation. This is a crude measure of how much ‘escaping’ there is in the string.
Omitted if the `signals` analysis task was not run or there is no data.

#### `base64_strings`
Substrings of string literals that match a base64-like regex. Omitted if the `signals` analysis task was not run or there is no data.

#### `hex_strings`
Substrings of at least 16 hexadecimal digits found in string literals. Omitted if the `signals` analysis task was not run or there is no data.

#### `ip_addresses`
Substrings of string literals that match an IP address-like regex (both IPv4 and IPv6). Omitted if the `signals` analysis task was not run or there is no data.

#### `urls`
Substrings of string literals that match an URL-like regex. Omitted if the `signals` analysis task was not run or there is no data.



### `js` object

#### `identifiers`
List of source code identifiers found in the file. Each record contains the following fields:
`name` - symbol name in the source code
`type` - type of symbol, for example function or class name
`entropy` - estimated entropy of the identifier name

#### `string_literals`
List of string literals found in the file. Each record contains the following fields:
`value` - String value of the literal as appears in memory
`raw` - String representation exactly as appears in the source code
`entropy` - Estimated entropy of the value

#### `int_literals`

List of integer literals found in the file. Each record contains the following fields:
`value` - Integer value of the literal as appears in memory
`raw` - String representation exactly as appears in the source code

#### `float_literals`

List of floating point literals found in the file. Each record contains the following fields:
`value` - Floating point value of the literal as appears in memory
`raw` - String representation exactly as appears the source code

#### `comments`
List of comments found in the file. Each record contains the following fields:
`text` - Raw comment text


